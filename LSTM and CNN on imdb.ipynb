{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (20000,)\n",
      "Shape of Test data: (25000,)\n",
      "Shape of CV data: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,test_size = 0.2)\n",
    "print(\"Shape of train data:\", X_train.shape)\n",
    "print(\"Shape of Test data:\", X_test.shape)\n",
    "print(\"Shape of CV data:\", X_cv.shape)\n",
    "\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 600\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "X_cv = sequence.pad_sequences(X_cv,maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 600, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 373,301\n",
      "Trainable params: 373,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 151s 8ms/step - loss: 0.6192 - acc: 0.6705 - val_loss: 0.5143 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77520, saving model to weights_best.hdf5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.3874 - acc: 0.8384 - val_loss: 0.3575 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77520 to 0.84960, saving model to weights_best.hdf5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 91s 5ms/step - loss: 0.2970 - acc: 0.8810 - val_loss: 0.3927 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84960 to 0.85500, saving model to weights_best.hdf5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 94s 5ms/step - loss: 0.3103 - acc: 0.8785 - val_loss: 0.3824 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85500\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 96s 5ms/step - loss: 0.2639 - acc: 0.9028 - val_loss: 0.4119 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.85500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c42d88cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=256,verbose = 1,callbacks = callbacks_list,validation_data=(X_cv,y_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 42s 2ms/step\n",
      "Accuracy: 85.11%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.load_weights(\"weights_best.hdf5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test, y_test, verbose=1,batch_size = 256)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 600, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 600, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 300, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 376,405\n",
      "Trainable params: 376,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 44s 2ms/step - loss: 0.5821 - acc: 0.6874 - val_loss: 0.3666 - val_acc: 0.8464\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84640, saving model to weights_best_cnn.hdf5\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.2665 - acc: 0.8931 - val_loss: 0.2865 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84640 to 0.88900, saving model to weights_best_cnn.hdf5\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 45s 2ms/step - loss: 0.1647 - acc: 0.9403 - val_loss: 0.2977 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88900 to 0.89080, saving model to weights_best_cnn.hdf5\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.1212 - acc: 0.9586 - val_loss: 0.3978 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89080\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.0885 - acc: 0.9724 - val_loss: 0.3396 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c591ae400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "filepath=\"weights_best_cnn.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=256,verbose = 1,callbacks = callbacks_list,validation_data=(X_cv,y_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 600, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 600, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 300, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 376,405\n",
      "Trainable params: 376,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 87.98%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.load_weights(\"weights_best_cnn.hdf5\")\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|     Model      | Accuracy |\n",
      "+----------------+----------+\n",
      "|      LSTM      |   85.5   |\n",
      "| CNN using LSTM |   87.5   |\n",
      "+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'Accuracy']\n",
    "table.add_row(['LSTM', 85.50])\n",
    "table.add_row(['CNN using LSTM', 87.50])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
